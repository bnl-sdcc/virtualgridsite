\documentclass[a4paper]{jpconf}
\usepackage{graphicx}
\graphicspath{ {images/} }
\usepackage{subfig}
\usepackage{afterpage}
\usepackage{lmodern}
\usepackage{xcolor}
\definecolor{htcondorbox}{RGB}{200,200,200}
\usepackage{lineno}
\usepackage{newfloat}
\DeclareFloatingEnvironment[fileext=lop]{snippet}
\linenumbers


\begin{document}
\title{Interfacing HTCondor-CE with OpenStack}

\author{B. Bockelman$^1$, J. Caballero Bejar$^2$, J. Hover $^2$}

\address{$^1$ University of Nebraska-Lincoln, Lincoln, NE 68588, USA}
\address{$^2$ Brookhaven National Laboratory, PO BOX 5000 Upton, NY 11973, USA}

\ead{bbockelm@cse.unl.edu, jcaballero@bnl.gov, jhover@bnl.gov}

\begin{abstract}
Over the past few years, Grid Computing technologies have reached a high level of maturity. 
One key aspect of this success has been the development and adoption of newer Compute Elements to interface the external Grid users with local batch systems. 
These new Compute Elements allow for better handling of jobs requirements and a more precise management of diverse local resources.

However, despite this level of maturity, the Grid Computing world is lacking diversity in local execution platforms. 
As Grid Computing technologies have historically been driven by the needs of the High Energy Physics community, 
most resource providers run the platform (operating system version and architecture) that best suits the needs of their particular users.

In parallel, the development of virtualization and cloud technologies has accelerated recently, 
making available a variety of solutions, both commercial and academic, proprietary and open source. 
Virtualization facilitates performing computational tasks on platforms not available at most computing sites.

This work attempts to join the technologies, allowing users to interact with computing sites through one of the standard Computing Elements, HTCondor-CE,
but running their jobs within VMs on a local cloud platform, OpenStack, when needed.

The system will re-route, in a transparent way, 
end user jobs into dynamically-launched VM worker nodes when they have requirements that cannot be satisfied by the static local batch system nodes. 
Also, once the automated mechanisms are in place, it becomes straightforward to allow an end user to invoke a custom Virtual Machine at the site. 
This will allow cloud resources to be used without requiring the user to establish a separate account. Both scenarios are described in this work.
\end{abstract}

\section{Introduction}

In parallel to the evolution of the Grid Computing technologies, a plethora of
virtualization tools and techniques have been developed, both in industry and academia.
Grid Computing has reached a high level of maturity in certain aspects, but it
lacks some flexibility in others.
In particular, the type of flexibility that virtualization tools can offer. 
For historical reasons Grid Computing technology has evolved around the needs of the High Energy Physics (HEP) community, 
which has a very limited set of requirements, but those are in fact almost
unavoidable. One example of these contraints is the need for a specific Linux
platform to be deployed on worker node resources within the HEP-oriented
Grid infrastructure.

~

This scenario is highly efficient for the HEP experiments, 
but may present a barrier for other scientific communities.

~

On the other hand, many scientific and academia facilities offer to their employees -or even to external scientist-,
the ability to use virtualization platforms. 
Several of these platforms have become very mature products over the past years.
Some very popular examples are OpenNebula \cite{opennebula} and OpenStack \cite{openstack}.
The usage of these virtualized resources eliminates the contraints in the
classic Grid infrastructure, but forces the users to learn how to use them,
including installing client tools and getting virtualization-specific
user accounts.

~

The goal of this work is to bring both worlds, the Grid Computing and the virtualization, closer to each other. 
We study how to allow users to submit their grid jobs to a standard Compute Element -the HTCondor-CE \cite{condorce} in this work-,
expressing platform requirements that do not necesarily fit the classical HEP-oriented environment.
Also, we present a mechanism to let users to interact with a virtualization cluster without requiring
special knowledge, the installation of virtualization-specific client software,
or virtualization-specific user credentials.

\subsection{Prototype setup} \label{prototype}

~

The setup for this prototype was simple. 
All grid identities were mapped at the CE as a single UNIX account, which
corresponds to a unique OpenStack tenant.
The back-end batch system was also HTCondor \cite{condor}.
The VM images used in OpenStack had an HTCondor startd preconfigured to join the
existing HTCondor pool.
These startd daemons were also preconfigured to shut down after the first job finished, in order to prevent them from picking more than one job. 

Also, job submission was done one by one.

The technical specifications of the OpenStack cluster used for this prototype are as listed 

\begin{itemize}
\item OpenStack instance: Icehouse.
\item 120 compute nodes (16 cores, 32 GM RAM, 2 to 5 TB disks).
\item 200 TB Swift (Amazon S3-equivalent) object store.
\item EC2 API enabled.
\end{itemize}

The version of HTCondor was 8.4.8.

\section{Prototype description}

~

In order to allow the HTCondor-CE to decide when jobs need to be executed on a
compute server within OpenStack instead of any of nodes in the backend batch
system, we make use of one feature included in the CE: the JobRouter hooks \cite{jobrouter} \newline
The Job Router is, by definition, an add-on that transforms jobs from one type to
another according to a configurable policy.
The Job Router hooks are arbitrary code that can be invoked at some points during the job life cycle.
Example on how to set HTCondor-CE to use hooks can be seen in Snippet \ref{snip:snippet1} 

%\begin{figure}[h!]
%    \colorbox{htcondorbox}{
%        \begin{minipage}{\textwidth}
%        \small
%            \bf{JOB\_ROUTER\_HOOK\_KEYWORD = NOVA \newline \newline
%                NOVA\_HOOK\_TRANSLATE\_JOB = /usr/share/virtualgridsite/nova\_hook\_translate\_job \newline
%                NOVA\_HOOK\_UPDATE\_JOB\_INFO = /usr/libexec/nova\_hook\_update\_job\_info \newline
%                NOVA\_HOOK\_JOB\_EXIT = /usr/libexec/nova\_hook\_job\_exit \newline
%                NOVA\_HOOK\_JOB\_CLEANUP = /usr/libexec/nova\_hook\_cleanup\_job
%            }
%        \end{minipage}
%    }
%\caption{snippet 1}
%\label{snippet1}
%\end{figure}

%\begin{center}
%    \colorbox{htcondorbox}{
%        \begin{minipage}{\textwidth}
%        \small
%            \bf{JOB\_ROUTER\_HOOK\_KEYWORD = NOVA \newline \newline
%                NOVA\_HOOK\_TRANSLATE\_JOB = /usr/share/virtualgridsite/nova\_hook\_translate\_job \newline
%                NOVA\_HOOK\_UPDATE\_JOB\_INFO = /usr/libexec/nova\_hook\_update\_job\_info \newline
%                NOVA\_HOOK\_JOB\_EXIT = /usr/libexec/nova\_hook\_job\_exit \newline
%                NOVA\_HOOK\_JOB\_CLEANUP = /usr/libexec/nova\_hook\_cleanup\_job
%            }
%        \end{minipage}
%    }
%\end{center}

%\begin{figure}[h]
\begin{snippet}[h]
    \renewcommand\figurename{Snippet}
    \centering
    \includegraphics[width=0.95\textwidth]{snippet1.png}
    \caption{example of HTCondor-CE setup for hooks}
    \label{snip:snippet1}
\end{snippet}
%\end{figure}


\subsection{Case 1: elastic expansion}

~

The first scenario allows running user's job within OpenStack when
the job's requirements do not match the characteristics of the physical nodes in
the backend batch system.
A typical case is when user's job requires and older version of the operating
system, or a newer one.
Job's requirements are listed in Table \ref{table:classad1}


\begin{table}[h]
\centering
\begin{tabular}{ l l }
  \hline
  \textbf{job classad} & \textbf{description} \\
  \hline
  +opsys & Type of the OS. Example: LINUX  \\
  +opsysname & Name of OS. Example: CentOS \\
  +opsysmajorversion & Version of the OS. Example: 7 \\
  +maxMemory & Amount of RAM memory needed. \\
  +disk & Hard disk size \\
  +xcount & Number of cores \\
  \hline
\end{tabular}
\caption{Job's classad}
\label{table:classad1}
\end{table}

~

The process is shown in \ref{fig:elastic}. 
The HTCondor-CE's TRANSLATE hook compares the job's requirements with a set of
configuration files compiling the entire list of host profiles available, 
both in the back-end batch system and VM images ready to be used in OpenStack.
As a result of that comparison, when it decides a new VM-based worker is needed
to run the job, it directly requests that OpenStack boot the appropriate VM.
As mentioned, the VMs are prepared to initialize an HTCondor's startd daemon and
join the back-end pool.
Once the VM booting process has finished, the TRANSLATE hook finalizes and the source job gets routed to the backend pool,
with the guarantee that there is now a host that can run it. 
It also added a new ad-hoc classad to the job with the name assigned to the VM
worker.

~

The job execution finalization triggers a call to the CLEANUP hook.
This hook will note the previously mentioned custom classad, and wil then
proceed with the termination of the VM server.


\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{opportunistic.png}
    \caption{Sequence diagram for the elastic case}
    \label{fig:elastic}
\end{figure}


\subsection{Case 2: interactive usage}

In this case, the user knows there is an OpenStack cluster behind the CE, 
and she actually wants to boot a general-purpose VM host to log into and work
interactively. In this case there is no HTCondor startd on the VM, and there is no payload to be executed in this case.

~

This request for an interactive VM is expressed by adding a special job classad: 
\begin{center}
    +virtualgridsite\_interactive\_vm = true
\end{center}

~

As can be seen in Figure \ref{fig:interactive}, when the TRANSLATE hook detects that job classad, 
it transforms the job in place -so it is not routed to any back-end batch
queue-, and it is converted into an EC2 job \cite{condorec2}.
This works because, as mentioned in section \ref{prototype}, the OpenStack infrastructure has the EC2 API enabled. 

\begin{figure}[h]
    \centering
    \includegraphics[width=0.4\textwidth]{dedicated.png}
    \caption{Sequence diagram for the interactive usage case}
    \label{fig:interactive}
\end{figure}

In this scenario, it is the routed job, now converted into an EC2 job, 
which is in charge of requesting the VM instantiation in OpenStack.
Once that step is completed, the user can read the public IP of that new VM server, and log into it. 
This IP is available because it is written as a job classad that is set to be
mirrored back with the following setting

%\begin{figure}[h]
\begin{snippet}[h]
    \centering
    \renewcommand\figurename{Snippet}
    \includegraphics[width=0.95\textwidth]{snippet2.png}
    \caption{Setup for classads to be transferred}
    \label{snip:snippet2}
\end{snippet}
%\end{figure}

%\begin{center}
%    \colorbox{htcondorbox}{
%        \begin{minipage}{\textwidth}
%        \small
%            \bf{NOVA\_ATTRS\_TO\_COPY = EC2ElasticIP
%            }
%        \end{minipage}
%    }
%\end{center}

Once the user no longer wants the VM, she can issue a \textit{condor\_rm}
command, which will remove the running job. 
Once again, that event will be captured by the CLEANUP hook, which will execute
code to terminate the corresponding VM instance.


\subsection{Custom virtual machine image}

~

Users can, if they prefer, provide the VM image they need themselves. 
This is done by passing URL pointing at the VM image as a job classad:
\begin{center}
    +virtualgridsite\_url = \textless URL with the image \textgreater
\end{center}

As can be seen in Figure \ref{fig:custom}, 
the only difference with respect the previous cases is that the new VM image is uploaded into Glance -the OpenStack image service- when needed.
This image is uploaded with an unique name, 
created as a combination of the URL hash and its timestamp. 
This way it becomes trivial to determine whether the requested image has already being uploaded or not. 

\begin{figure}[h]
    \centering
    \subfloat[elastic case]{{\includegraphics[width=0.45\textwidth]{opportunistic_custom.png} }}%
    \qquad
    \subfloat[interactive usage]{{\includegraphics[width=0.42\textwidth]{dedicated_custom.png} }}%
    \caption{Sequence diagrams when using user's custom image}%
    \label{fig:custom}%
\end{figure}


\section{Security}

~

Because the configuration files, as well as the OpenStack credential files, 
are placed on the same CE host, it is important to prevent the user's jobs from running on that host.
This is prevented by adding the following setup.


%\begin{figure}[h]
\begin{snippet}[h]
    \centering
    \renewcommand\figurename{Snippet}
    \includegraphics[width=0.95\textwidth]{snippet3.png}
    \caption{Setup to prevent user's jobs being forked at the HTCondor-CE host}
    \label{snip:snippet3}
\end{snippet}
%\end{figure}

%\begin{center}
%    \colorbox{htcondorbox}{
%        %\begin{minipage}{0.95\textwidth}
%        \begin{minipage}{\textwidth}
%        \small
%            \bf{START\_LOCAL\_UNIVERSE = False \newline
%                START\_SCHEDULER\_UNIVERSE = \$(START\_LOCAL\_UNIVERSE)
%            }
%        \end{minipage}
%    }
%\end{center}


\section{Problems found}

~

Several limitations were found during this investigation.
Some of these limitations are currently being fixed in the HTCondor source code.
Deeper understanding of the others may lead to improvements in the overall
job-routing system.

~

If the communication process with OpenStack by the TRANSLATE hook fails, 
there is not currently a clean way to terminate the job, or to put it in a HOLD
state. Instead, the Job Router tries again, after 30 seconds, in an infinite loop.

~

For the mirroring of the classads from the routed job back to the source job, 
it is required that the UPDATE hook send the whole classad to standard output. 
It has been found that actions fail due to hidden bugs in the code. 

~

It is not easy to manage a job when its requirements cannot be satisfied by any
node in the backend batch system nor any currently available VM image. 
The solution implemented, for the time being, is to detect that case early in
the job cycle management, and create a dedicated route for it. 
To detect this case, we leverage a feature that allows for the partial creation of the routing table by code.
This code reads the configuration files with all avaible images types, and builds the logic to identify jobs that do not meet any of those criteria. 
When this ocurrs, the job is transformed in place -and therefore not routed to
the backend batch queue-, with an extra classad (set\_noroute=True) to prevent it from being considered again for routing.
This leaves the job in permanent IDLE status, making it a candidate for
explicit removal. It can also be cleaned up automatically if a
periodic\_remove expression is added to its classad definition.

%\begin{figure}[h]
\begin{snippet}[h]
    \centering
    \renewcommand\figurename{Snippet}
    \includegraphics[width=0.95\textwidth]{snippet4.png}
    \caption{location of code with routing policies}
    \label{snip:snippet4}
\end{snippet}
%\end{figure}

%\begin{center}
%    \colorbox{htcondorbox}{
%        \begin{minipage}{\textwidth}
%        \small
%            \bf{JOB\_ROUTER\_ENTRIES\_CMD = \newline 
%                \hspace*{1cm}/usr/lib/python2.6/site-packages/virtualgridsite/routes.py \newline
%                JOB\_ROUTER\_ENTRIES\_REFRESH = 600
%            }
%        \end{minipage}
%    }
%\end{center}

%\begin{figure}[h]
\begin{snippet}[h]
    \centering
    \renewcommand\figurename{Snippet}
    \includegraphics[width=0.95\textwidth]{snippet5.png}
    \caption{Example of routing table to manage jobs with requirements that cannot be satisfied}
    \label{snip:snippet5}
\end{snippet}
%\end{figure}

%\begin{center}
%    \colorbox{htcondorbox}{
%        \begin{minipage}{\textwidth}
%        \small
%            \bf{[
%                 Name = "No\_route";  \newline
%                 EditJobInPlace = true; \newline
%                 set\_noreroute = "True"; \newline
%                 Requirements = TARGET.noreroute is undefined \&\& \textless node requirements\textgreater;  \newline
%                 set\_PeriodicRemove = ( JobStatus == 1 \&\& ( time() - EnteredCurrentStatus ) \textgreater \ 10 ); \newline
%                 TargetUniverse = 5 \newline
%                 ]
%            }
%        \end{minipage}
%    }
%\end{center}

~

Another problem found is related to the present configuration after installation rather than code design. 
The HTCondor-CE only allows, by default, jobs being routed in certain ways -more exactly, to certain Job Universes-.
It is easy to workaround this constraint by overriding the right configuration
variable (JOB\_ROUTER\_SOURCE\_SOURCE\_JOB\_CONSTRAINT), removing that specific
constraint.

%\begin{figure}[h]
\begin{snippet}[h]
    \centering
    \renewcommand\figurename{Snippet}
    \includegraphics[width=0.95\textwidth]{snippet6.png}
    \caption{overriding the default Job Router constrains}
    \label{snip:snippet6}
\end{snippet}
%\end{figure}

%\begin{center}
%    \colorbox{htcondorbox}{
%        \begin{minipage}{\textwidth}
%        \small
%            \bf{JOB\_ROUTER\_SOURCE\_JOB\_CONSTRAINT = \newline
%               (target.x509userproxysubject =!= UNDEFINED) \&\& \newline
%               (target.x509UserProxyExpiration =!= UNDEFINED) \&\& \newline
%               (time() \textless \  target.x509UserProxyExpiration)
%            }
%        \end{minipage}
%    }
%\end{center}

\section{Future work}

This work can be improved in several ways. 

~

First, it should be straigthforward to expand the same concept to other
platforms beyond OpenStack. For example, to AWS, 
or remote clusters using the BOSCO-CE mechanism.

~

The presetup in the VM images should be avoided, allowing the HTCondor startd to join any arbitrary pool.

~

The job lifecycle management allows for improvements. 
One possibility is to allow the same VM worker to run more than one job,
increasing the efficiency of the whole system. Another option is to reuse the
presented mechanism to elastically expand the size of the local back-end batch
queue when the jobs waiting time passes some threshold.

~

Having more than just one OpenStack user (tenant) is highly recommended to allow
the usage of user quotas, fair share mechanisms, and to enable per-tenant
accounting and billing.

~

Removing the need for GSI authentication to submit jobs to the HTCondor-CE is under consideration.

~

We are also considering a change in the architectural design to prevent the
hooks code from interacting directly with OpenStack. Instead, an independent
daemon would listen to the hooks' requests and execute the corresponding steps.
This will avoid the need to re-read the configuration files for each job, 
and also allows for having a single process which holds the state of the entire
system, including all jobs. This centralization could facilitate the
implementation of more complex and smarter policies.
 


%%\section{Acknowledgements}
\ack{
The authors would like to thank the HTCondor developers for their constant support.
}


\section*{References}{}

\bibliographystyle{iopart-num}
\bibliography{references}

~

Notice:
This manuscript has been authored by employees of Brookhaven Science Associates,
LLC under Contract No. DE-AC02-98CH10886 with the U.S. Department of Energy.
The publisher by accepting the manuscript for publication acknowledges
that the United States Government retains a non-exclusive, paid-up, irrevocable,
world-wide license to publish or reproduce the published form of this manuscript,
or allow others to do so, for United States Government purposes.

\end{document}
